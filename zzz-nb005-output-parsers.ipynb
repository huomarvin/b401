{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# 输出解析器\n",
    "* 格式化LLM的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* 注意：由于目前市场上最佳的 LLM 是 OpenAI，我们将默认使用它。您将在下一课中看到如何连接其他开源 LLM，例如 Llama3 或 Mistral。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1d17b-6d15-423b-b554-26d6d977ca27",
   "metadata": {},
   "source": [
    "## LLM 模型\n",
    "* chatGPT-4 发布前的趋势。\n",
    "* 在 [这里](https://python.langchain.com/v0.1/docs/modules/model_io/llms/) 查看有关 LLM 模型的 LangChain 文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92628f2-62e8-436c-92d4-e849de7744ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31346a0c-ee9c-4a80-8e8a-85ef682df7c3",
   "metadata": {},
   "source": [
    "## 聊天模型\n",
    "* chatGPT-4 发布后的总体趋势。\n",
    "    * 通常称为“聊天机器人”。\n",
    "    * 人类与 AI 之间的对话。\n",
    "    * 可以有一个系统提示来定义 AI 的语气或角色。\n",
    "* 请查看 LangChain 文档中有关聊天模型的内容 [这里](https://python.langchain.com/v0.1/docs/modules/model_io/chat/)。\n",
    "* 默认情况下，我们将使用 ChatOpenAI。请查看有关它的 LangChain 文档页面 [这里](https://python.langchain.com/v0.1/docs/integrations/chat/openai/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b14d27c3-0b1b-4b11-a883-8da2734f21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721c4a4-56d6-48e2-b9db-0de0309c492a",
   "metadata": {},
   "source": [
    "## 解析输出\n",
    "* 请查看相应的 LangChain 文档页面 [这里](https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/)。\n",
    "* 语言模型输出文本。但有时我们希望以不同的格式获得这些答案，例如 JSON 字典或 XML 文档。为了实现这一点，我们使用输出解析器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177b19be-ea45-4ecb-a4dc-914da7958de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with an `answer` key that answers the following question: {question}\"\n",
    ")\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "json_chain = json_prompt | llmModel | json_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4ed2-f174-4177-b38d-b03397e4f2a7",
   "metadata": {},
   "source": [
    "#### 先前的提示模板包含了解析器说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "047f7986-5502-4205-9a7a-e7e7e26f51a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb755d4-4a0f-486a-99dd-ea1873eb7c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Russia'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_chain.invoke({\"question\": \"What is the biggest country?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1181d87-13df-4abf-9910-0b44618642de",
   "metadata": {},
   "source": [
    "#### Optionally, you can use Pydantic to define a custom output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdcf2860-9b94-46f9-94f8-81ce173b8ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873de824-c105-4e36-b4a7-d4bb498efc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic Object with the desired output format.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7006219-e78f-4f1f-8d8a-559679f84845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle find its way home?\",\n",
       " 'punchline': 'Because it lost its bearings!'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parser referring the Pydantic Object\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# Add the parser format instructions in the prompt definition.\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Create a chain with the prompt and the parser\n",
    "chain = prompt | chatModel | parser\n",
    "\n",
    "chain.invoke({\"query\": \"Tell me a joke.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

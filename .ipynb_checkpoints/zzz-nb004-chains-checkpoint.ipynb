{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# 链接\n",
    "* 按特定顺序执行多个操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1d17b-6d15-423b-b554-26d6d977ca27",
   "metadata": {},
   "source": [
    "## LLM 模型\n",
    "* 在 chatGPT-4 发布之前的趋势。\n",
    "* 请参阅 LangChain 文档了解 LLM 模型 [这里](https://python.langchain.com/v0.1/docs/modules/model_io/llms/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92628f2-62e8-436c-92d4-e849de7744ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31346a0c-ee9c-4a80-8e8a-85ef682df7c3",
   "metadata": {},
   "source": [
    "## 聊天模型\n",
    "* chatGPT-4 发布后的整体趋势。\n",
    "    * 通常被称为“聊天机器人”。\n",
    "    * 人类与人工智能之间的对话。\n",
    "    * 可以有一个系统提示来定义人工智能的语气或角色。\n",
    "* 关于聊天模型的 LangChain 文档请见 [这里](https://python.langchain.com/v0.1/docs/modules/model_io/chat/)。\n",
    "* 默认情况下，我们将使用 ChatOpenAI。有关它的更多信息，请参见 [这里](https://python.langchain.com/v0.1/docs/integrations/chat/openai/) 的 LangChain 文档页面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b14d27c3-0b1b-4b11-a883-8da2734f21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f91601-8594-41d3-9316-d51791fc54e8",
   "metadata": {},
   "source": [
    "## 提示\n",
    "* 请查看关于提示的LangChain文档 [这里](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/quick_start/)。\n",
    "* 输入到大型语言模型（LLMs）。\n",
    "* 提示模板：使用变量的更易用的提示。提示模板可以包括：\n",
    "    * 指令，\n",
    "    * 少量示例，\n",
    "    * 以及适合特定任务的具体上下文和问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5383c7e-7e62-46d0-8bef-17ff45a88495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nDuring John F. Kennedy\\'s presidency, his brother Robert F. Kennedy, who served as Attorney General, had a unique way of dealing with stress. He would often go down to the White House kitchen and bake pies. This became a well-known secret among the White House staff, who would often receive freshly baked pies from RFK himself.\\n\\nOne day, while baking a lemon meringue pie, RFK accidentally spilled some of the filling on his shirt. Not wanting to go back to work with a stained shirt, he quickly took it off and asked one of the kitchen staff to wash it for him. The staff member, not realizing whose shirt it was, took it home to his wife to wash.\\n\\nThe next day, the staff member\\'s wife was watching the news and saw RFK giving a press conference, wearing the same shirt that she had just washed. She immediately recognized it as her husband\\'s work and called the White House to inform them. The Kennedy family found the situation amusing and invited the staff member and his wife to the White House for a private tour.\\n\\nFrom then on, RFK\\'s secret baking sessions became a regular occurrence and the staff member\\'s wife became the official \"pie washer\" for the Kennedy family. It was a special and unique bond'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} story about {topic}.\"\n",
    ")\n",
    "\n",
    "llmModelPrompt = prompt_template.format(\n",
    "    adjective=\"curious\", \n",
    "    topic=\"the Kennedy family\"\n",
    ")\n",
    "\n",
    "llmModel.invoke(llmModelPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beb7dbcd-524c-4acc-9b65-0b209a170ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an {profession} expert on {topic}.\"),\n",
    "        (\"human\", \"Hello, Mr. {profession}, can you please answer a question?\"),\n",
    "        (\"ai\", \"Sure!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    profession=\"Historian\",\n",
    "    topic=\"The Kennedy family\",\n",
    "    user_input=\"How many grandchildren had Joseph P. Kennedy?\"\n",
    ")\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7585be48-9a19-43ab-a275-8ef6a04246a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Joseph P. Kennedy, the patriarch of the Kennedy family, had a total of 34 grandchildren. These grandchildren are the descendants of his nine children, including President John F. Kennedy, Senator Robert F. Kennedy, and other members of the Kennedy clan.', response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 55, 'total_tokens': 106}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0938d507-1e35-4586-b18d-0b4aa08cb7ce-0', usage_metadata={'input_tokens': 55, 'output_tokens': 51, 'total_tokens': 106})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1373ca0b-342f-4ac6-a697-5e2ad30bfa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Joseph P. Kennedy, the patriarch of the Kennedy family, had a total of 34 grandchildren. These grandchildren are the descendants of his nine children, including President John F. Kennedy, Senator Robert F. Kennedy, and other members of the Kennedy clan.' response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 55, 'total_tokens': 106}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-0938d507-1e35-4586-b18d-0b4aa08cb7ce-0' usage_metadata={'input_tokens': 55, 'output_tokens': 51, 'total_tokens': 106}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f6a5e25-e177-4d7a-ba29-6834a6a8152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph P. Kennedy, the patriarch of the Kennedy family, had a total of 34 grandchildren. These grandchildren are the descendants of his nine children, including President John F. Kennedy, Senator Robert F. Kennedy, and other members of the Kennedy clan.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b510dd0-33b7-4737-aef2-c52a1e8bbf41",
   "metadata": {},
   "source": [
    "#### ChatPromptTemplate的全部潜力是什么？\n",
    "* 请查看LangChain API中的[相应页面](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f8be09-99fc-491e-babb-0b8ad5bc74c2",
   "metadata": {},
   "source": [
    "## 我们的第一个链：少量示例提示的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "301ae08a-e223-4239-8eca-8468ceb1e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b882accd-e3e7-4e8a-9d85-55ebaa945837",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"¡hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"¡adiós!\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b973d828-0f47-4c43-98ab-e3db306d41e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¿Quién fue JFK?', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 52, 'total_tokens': 58}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c6f8ebf0-580f-43a6-8045-09511c0c84bd-0', usage_metadata={'input_tokens': 52, 'output_tokens': 6, 'total_tokens': 58})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chatModel\n",
    "\n",
    "chain.invoke({\"input\": \"Who was JFK?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

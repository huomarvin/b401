{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec567d2-6d54-4378-82c7-cf3e54949896",
   "metadata": {},
   "source": [
    "# 连接与大型语言模型\n",
    "- 开始与ChatGPT对话。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57560a7e-4ade-4f20-aa6a-e2c50c928849",
   "metadata": {},
   "source": [
    "## Intro\n",
    "* Input: 我们发送给LLM的提示词.\n",
    "* Output: 从LLM返回的响应.\n",
    "* 我们可以切换并使用不同的LLM。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332b6e9-8164-4859-879c-f021a4dfd69d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LangChain将LLM划分为两种类型\n",
    "1. LLM模型：文本补全模型。\n",
    "2. 聊天模型：与一系列消息进行对话，并可以定义特定角色（系统提示）。这种类型已成为LangChain中使用最广泛的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42a3ca-fc4d-4b91-b3bc-a7304ec4d5f8",
   "metadata": {},
   "source": [
    "## 查看差异\n",
    "* 即使有时 LangChain 文档对此可能会感到困惑，事实是文本补全模型和聊天模型都是 LLM。\n",
    "* 但是，正如您在这个 [游乐场](https://platform.openai.com/playground/chat?models=gpt-4o) 中所看到的，它们有一些显著的差异。请注意，LangChain 中的聊天模型具有系统消息、人类消息（OpenAI 称之为“用户消息”）和 AI 消息（OpenAI 称之为“助手消息”）。\n",
    "* 自 chatGPT 发布以来，聊天模型成为最受欢迎的 LLM 类型，并在大多数 LLM 应用中使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f9501-fa9e-4830-95e2-537dff951cf1",
   "metadata": {},
   "source": [
    "## 可以与LangChain一起使用的LLM列表\n",
    "* 在[这里](https://python.langchain.com/v0.1/docs/integrations/llms/)查看列表。\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00a6725-81b3-4ea3-b39a-eb8f2ded91a2",
   "metadata": {},
   "source": [
    "#### 在虚拟代码工作室或您选择的编辑器中查看代码。\n",
    "* 打开虚拟代码工作室或您选择的编辑器。\n",
    "* 打开项目文件夹\n",
    "* 打开 001-connect-llm.py 文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "## 创建您的 .env 文件\n",
    "* 在 GitHub 仓库中，我们包含了一个名为 .env.example 的文件\n",
    "* 将该文件重命名为 .env 文件，这里是您将添加机密 API 密钥的地方。请记得包括：\n",
    "* OPENAI_API_KEY=您的_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=您的_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=您的项目名称"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "我们将把我们的LangSmith项目称为**001-connect-llm**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2746c97-9fa5-481c-8333-21de1504a087",
   "metadata": {},
   "source": [
    "## 追踪操作\n",
    "从现在开始，我们可以从 LangSmith 追踪该项目的操作 **和成本**：\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* 注意：由于目前市场上最好的大型语言模型是 OpenAI，我们将默认使用它。您将在下一课中看到如何连接其他开源大型语言模型，如 Llama3 或 Mistral。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1d17b-6d15-423b-b554-26d6d977ca27",
   "metadata": {},
   "source": [
    "## LLM模型\n",
    "* 在chatGPT-4发布之前的趋势。\n",
    "* 请参阅LangChain文档中的LLM模型[这里](https://python.langchain.com/v0.1/docs/modules/model_io/llms/)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92628f2-62e8-436c-92d4-e849de7744ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeaf300-5cb6-4df8-bcb9-1fe3c82e4b22",
   "metadata": {},
   "source": [
    "#### 调用：响应的所有文本一次性打印。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ade5fa-b487-4f32-bda7-0f9c41b096b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llmModel.invoke(\n",
    "    \"Tell me one fun fact about the Kennedy family.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a33285ef-4bb5-4fd6-9894-790c07a5468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nOne fun fact about the Kennedy family is that they have their own personalized crest, which includes symbols such as a lion, an eagle, and a ship's wheel, representing courage, strength, and leadership.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aa71043-4707-44b4-8d1f-8540d5d139b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "One fun fact about the Kennedy family is that they have their own personalized crest, which includes symbols such as a lion, an eagle, and a ship's wheel, representing courage, strength, and leadership.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c29ae-d60a-44c7-925c-20084c0b941e",
   "metadata": {},
   "source": [
    "#### 流式传输：一次打印一块文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158aa111-9167-444c-9b10-90b095eac390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "One fun fact about the Kennedy family is that President John F. Kennedy's favorite meal was New England fish chowder. He often requested it for meals at the White House and even had a special recipe created just for him."
     ]
    }
   ],
   "source": [
    "for chunk in llmModel.stream(\n",
    "    \"Tell me one fun fact about the Kennedy family.\"\n",
    "):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98101f10-6349-4f98-9fb7-a1400166cedc",
   "metadata": {},
   "source": [
    "#### temperature：更多或更少的创造力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac12473a-1ffd-4a22-852a-92e1e6374914",
   "metadata": {},
   "outputs": [],
   "source": [
    "creativeLlmModel = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325b9b2a-c61d-4264-81bf-71090f9b0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llmModel.invoke(\n",
    "    \"Write a short 5 line poem about JFK\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "679c1220-13ed-4251-ba4b-f8f1ba350f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "A leader with grace and charm,\n",
      "His words inspired and disarmed,\n",
      "JFK, a symbol of hope,\n",
      "With a vision beyond the scope,\n",
      "Forever remembered, his legacy will never depart.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31346a0c-ee9c-4a80-8e8a-85ef682df7c3",
   "metadata": {},
   "source": [
    "## 聊天模型\n",
    "* 在chatGPT-4发布后的总体趋势。\n",
    "    * 常被称为“聊天机器人”。\n",
    "    * 人类与人工智能之间的对话。\n",
    "    * 可以有一个系统提示来定义人工智能的语气或角色。\n",
    "* 请参阅LangChain文档中的聊天模型 [这里](https://python.langchain.com/v0.1/docs/modules/model_io/chat/)。\n",
    "* 默认情况下，我们将使用ChatOpenAI。有关详细信息，请参见[这里](https://python.langchain.com/v0.1/docs/integrations/chat/openai/)的LangChain文档页面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b14d27c3-0b1b-4b11-a883-8da2734f21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eaa967e-067f-4574-8cbc-b1e5b7956fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are an historian expert in the Kennedy family.\"),\n",
    "    (\"human\", \"Tell me one curious thing about JFK.\"),\n",
    "]\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f567f5a-c4ea-4234-84e6-422bf6104589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"One curious thing about JFK is that he was a collector of unique and eclectic items. He had a fascination with history and art, and his collection included everything from ship models and scrimshaw to original manuscripts and rare books. JFK's love of collecting even extended to quirky items like coconut shells carved with faces that he displayed in the Oval Office. This hobby provided a glimpse into his personal interests and served as a reflection of his intellectual curiosity.\", response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 29, 'total_tokens': 116}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b2f90721-52fe-4482-989a-bc75d6f3e7fd-0', usage_metadata={'input_tokens': 29, 'output_tokens': 87, 'total_tokens': 116})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19a6abd4-a072-47ea-ae60-7959def9b602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One curious thing about JFK is that he was a collector of unique and eclectic items. He had a fascination with history and art, and his collection included everything from ship models and scrimshaw to original manuscripts and rare books. JFK's love of collecting even extended to quirky items like coconut shells carved with faces that he displayed in the Oval Office. This hobby provided a glimpse into his personal interests and served as a reflection of his intellectual curiosity.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47927ac1-13bc-40eb-9917-9d39418f0f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 87,\n",
       "  'prompt_tokens': 29,\n",
       "  'total_tokens': 116},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7847143f-3179-423e-b499-a6e494967741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'AIMessage',\n",
       " 'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       " 'type': 'object',\n",
       " 'properties': {'content': {'title': 'Content',\n",
       "   'anyOf': [{'type': 'string'},\n",
       "    {'type': 'array',\n",
       "     'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "  'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "  'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "  'type': {'title': 'Type', 'default': 'ai', 'enum': ['ai'], 'type': 'string'},\n",
       "  'name': {'title': 'Name', 'type': 'string'},\n",
       "  'id': {'title': 'Id', 'type': 'string'},\n",
       "  'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "  'tool_calls': {'title': 'Tool Calls',\n",
       "   'default': [],\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/ToolCall'}},\n",
       "  'invalid_tool_calls': {'title': 'Invalid Tool Calls',\n",
       "   'default': [],\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/InvalidToolCall'}},\n",
       "  'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},\n",
       " 'required': ['content'],\n",
       " 'definitions': {'ToolCall': {'title': 'ToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'type': {'title': 'Type', 'enum': ['tool_call'], 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id']},\n",
       "  'InvalidToolCall': {'title': 'InvalidToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'error': {'title': 'Error', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'enum': ['invalid_tool_call'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error']},\n",
       "  'UsageMetadata': {'title': 'UsageMetadata',\n",
       "   'type': 'object',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens']}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54631efb-dbe2-4bd7-b588-324f19a28b2c",
   "metadata": {},
   "source": [
    "#### Before the previous one, the old way (but still very popular) of doing this was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a20ba943-ce6b-45e2-9dbb-351c48421069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b879a5f4-2250-4a70-b065-7796c4fe9f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an historian expert on the Kennedy Family.\"),\n",
    "    HumanMessage(content=\"How many children had Joseph P. Kennedy?\"),\n",
    "]\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78f9b26b-e7e1-4613-8e3e-0c81f8b54da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Joseph P. Kennedy and his wife Rose Fitzgerald Kennedy had nine children. Their children were Joseph Jr., John F. (JFK), Rosemary, Kathleen, Eunice, Patricia, Robert F. (Bobby), Jean, and Edward M. (Ted).', response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 30, 'total_tokens': 84}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-63964416-759f-461a-aecb-789b336ce0c1-0', usage_metadata={'input_tokens': 30, 'output_tokens': 54, 'total_tokens': 84})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41204f4-0cec-4039-a18d-2a25b9dd5efd",
   "metadata": {},
   "source": [
    "#### Streaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83d9f1d0-bba8-4885-9ac1-01fc273732b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph P. Kennedy and his wife Rose Kennedy had nine children: Joseph Jr., John F. (JFK), Rosemary, Kathleen, Eunice, Patricia, Robert (Bobby), Jean, and Edward (Ted)."
     ]
    }
   ],
   "source": [
    "for chunk in chatModel.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd276b9-494a-47c2-8455-2ff33fc4f221",
   "metadata": {},
   "source": [
    "#### Another old way, similar results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bc0210b-27e0-41ed-8ad8-ff1c75c9bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are expert {profession} in {topic}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chatModel\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"profession\": \"Historian\",\n",
    "        \"topic\": \"Kennedy Family\",\n",
    "        \"input\": \"Tell me one fun fact about JFK.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc436d53-b372-43eb-ac00-ee39c9fa491a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One fun fact about JFK is that he was the first president to hold a press conference that was broadcast live on television. This event took place on January 25, 1961, and it allowed the American public to see and hear their president in real-time, marking a significant shift in how political communication was conducted.', response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 28, 'total_tokens': 92}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3e6f4f2c-a7fe-4220-925e-1e3a6954cc57-0', usage_metadata={'input_tokens': 28, 'output_tokens': 64, 'total_tokens': 92})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512a50eb-dfe4-4d08-802e-c3dbc40a3444",
   "metadata": {},
   "source": [
    "## 如何从 Visual Studio Code 执行代码\n",
    "* 在 Visual Studio Code 中，查看文件 001-connect-llms.py\n",
    "* 在终端中，确保您位于文件所在目录，然后运行：\n",
    "    * python 001-connect-llm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d7c2f-57ed-43f5-b6ed-77c54243c069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
